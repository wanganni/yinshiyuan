# coding=utf-8
#!/usr/bin/env python3
import requests
import json
import urllib.parse
import re
import os
import time
from urllib3.exceptions import InsecureRequestWarning

# ç¦ç”¨SSLè­¦å‘Š
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

class KuaidiSpider:
    def __init__(self):
        self.host = "https://www.xjjkdfw.sbs"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Linux; Android 11; M2007J3SC Build/RKQ1.200826.002; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/77.0.3865.120 MQQBrowser/6.2 TBS/045713 Mobile Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Referer': self.host
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.session.verify = False
        print("å¿«é€’ğŸ”çˆ¬è™«åˆå§‹åŒ–å®Œæˆ")

    def fetch(self, url, headers=None, retry=3):
        """è¯·æ±‚ç½‘é¡µ"""
        for i in range(retry):
            try:
                if headers:
                    response = self.session.get(url, headers=headers, timeout=30)
                else:
                    response = self.session.get(url, timeout=30)
                response.encoding = 'utf-8'
                return response
            except Exception as e:
                print(f"è¯·æ±‚å¤±è´¥ {i+1}/{retry}: {str(e)}")
                time.sleep(2)
        return None

    def log(self, message):
        """æ—¥å¿—è¾“å‡º"""
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {message}")

    def get_categories(self):
        """è·å–å…¨éƒ¨åˆ†ç±»"""
        self.log("å¼€å§‹è·å–åˆ†ç±»...")
        try:
            rsp = self.fetch(self.host)
            if not rsp:
                return []
                
            html = rsp.text
            categories = []
            pattern = r'<a href="/vodtype/(\d+)\.html"[^>]*>([^<]+)</a>'
            matches = re.findall(pattern, html)
            
            seen = set()
            for tid, name in matches:
                if name.strip() and tid not in seen:
                    seen.add(tid)
                    categories.append({'type_id': tid, 'type_name': name.strip()})
            
            self.log(f"æ‰¾åˆ° {len(categories)} ä¸ªåˆ†ç±»")
            return categories
        except Exception as e:
            self.log(f"è·å–åˆ†ç±»å‡ºé”™: {str(e)}")
            return []

    def get_category_pages(self, tid):
        """è·å–åˆ†ç±»çš„æ€»é¡µæ•°"""
        try:
            url = f"{self.host}/vodtype/{tid}.html"
            rsp = self.fetch(url)
            if not rsp:
                return 1
                
            html = rsp.text
            page_links = re.findall(r'<a href="/vodtype/{}/page/(\d+)\.html"'.format(tid), html)
            if page_links:
                pagecount = max([int(p) for p in page_links if p.isdigit()])
                return pagecount
            return 1
        except:
            return 1

    def get_videos_from_page(self, tid, pg):
        """ä»åˆ†ç±»é¡µé¢è·å–è§†é¢‘åˆ—è¡¨"""
        try:
            if pg == 1:
                url = f"{self.host}/vodtype/{tid}.html"
            else:
                url = f"{self.host}/vodtype/{tid}/page/{pg}.html"
            
            self.log(f"è·å–åˆ†ç±» {tid} ç¬¬ {pg} é¡µ: {url}")
            rsp = self.fetch(url)
            if not rsp:
                return []
                
            html = rsp.text
            videos = self._get_videos(html)
            return videos
        except Exception as e:
            self.log(f"è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥: {str(e)}")
            return []

    def _get_videos(self, html):
        """ä»HTMLä¸­æå–è§†é¢‘åˆ—è¡¨"""
        videos = []
        
        pattern = r'<a\s+class="thumbnail"[^>]*href="(/vodplay/(\d+)-\d+-\d+\.html)"[^>]*>.*?data-original="([^"]+)".*?</a>.*?<a\s+href="/voddetail/\d+\.html"[^>]*>([^<]+)</a>.*?<p\s+class="vodtitle">([^<]+?)\s*-\s*<span\s+class="title">([^<]+)</span>'
        
        matches = re.findall(pattern, html, re.DOTALL | re.IGNORECASE)
        
        for full_play_link, vid, pic, title, category, date in matches:
            if not pic.startswith('http'):
                pic = self.host + pic if pic.startswith('/') else 'https:' + pic if pic.startswith('//') else pic
            
            video = {
                'vod_id': vid,
                'vod_name': title.strip(),
                'vod_pic': pic,
                'vod_remarks': f"{category.strip()} | {date.strip()}",
                'play_url': f"{self.host}/vodplay/{vid}-1-1.html"
            }
            videos.append(video)
        
        return videos

    def get_video_detail(self, vid):
        """è·å–è§†é¢‘è¯¦æƒ…å’Œæ’­æ”¾é“¾æ¥"""
        try:
            detail_url = f"{self.host}/voddetail/{vid}.html"
            self.log(f"è·å–è§†é¢‘è¯¦æƒ…: {detail_url}")
            
            rsp = self.fetch(detail_url)
            if not rsp:
                return None
                
            html = rsp.text
   